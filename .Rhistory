install.packages("devtools")
devtools::install_github("macmillancontentscience/morphemepiece")
devtools::install_github("macmillancontentscience/morphemepiece")
print(word)
word<-"hello"
word <- "hello"
word <- "hello"
print(word)
word <- "hello"
print(word)
word <- "hello"
word <- "hello"
print(word)
devtools::install_github("macmillancontentscience/morphemepiece")
devtools::install_github("macmillancontentscience/morphemepiece") force=TRUE
devtools::install_github("macmillancontentscience/morphemepiece") 'force=TRUE'
devtools::install_github("macmillancontentscience/morphemepiece") force = TRUE
devtools::install_github("macmillancontentscience/morphemepiece", force = TRUE)
library(morphemepiece)
tokenized_words=.mp_tokenize_word("test")
print(tokenized_words)
library(morphemepiece)
tokenized_words=morphemepiece::.mp_tokenize_word("test")
print(tokenized_words)
library(morphemepiece)
tokenized_words <- morphemepiece::.mp_tokenize_word("test")
print(tokenized_words)
library(morphemepiece)
function_a <- morphemepiece::.mp_tokenize_word
import::from(morphemepiece, tokenized_words)
import::from(morphemepiece_tokenize())
load(morphemepiece_tokenize())
tokenized<-morphemepiece_tokenize("hello there")
print(tokenized)
View(tokenized)
load(morphemepiece_tokenize())
tokenized_text<-morphemepiece_tokenize("hello there")
print(tokenized_text)
load(morphemepiece_tokenize())
tokenized_text<-morphemepiece_tokenize("hello there")
print("123")
print(tokenized_text)
load(morphemepiece_tokenize())
tokenized_text<-morphemepiece_tokenize(text="hello there")
print("123")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="hello there")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="hello there")
print(tokenized_text)
vocab<-morphemepiece.data::morphemepiece_vocab()
print(vocab)
tokenized_text<-morphemepiece_tokenize(text="hello there")
print(tokenized_text)
vocab<-morphemepiece::morphemepiece_vocab()
print(vocab)
tokenized_text<-morphemepiece_tokenize(text="a hello there")
print(tokenized_text)
vocab<-morphemepiece::morphemepiece_vocab()
print(vocab)
tokenized_text<-morphemepiece_tokenize(text="a hello there")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="a ab hello there")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="what the fuck")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="there is a the fuck")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
print(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
print(tokenized_text[1])
View(tokenized_text)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
print(tokenized_text[[1]])
print(tokenized_text[[1]])
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[1]
print(first_element)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[[1]]
print(first_element)
View(tokenized)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[['hello']]
print(first_element)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[["hello"]]
print(first_element)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text["hello"]
print(first_element)
View(first_element)
View(tokenized)
View(tokenized_text)
tokenized_text[[1]]
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[[1]]["hello"]
print(first_element)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[[1]]["my"]
print(first_element)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[[1]]["my"]
print(first_element+1)
tokenized_text<-morphemepiece_tokenize(text="hello my name is jan i'm glad to see you")
first_element<- tokenized_text[[1]]["my"]
print(first_element)
vocab<-morphemepiece_vocab()
View(tokenized_text)
print(morphemepiece_vocab())
library("morphemepiece")
print(morphemepiece_vocab())
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
print(vocab_split)
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
print(vocab_split$prefixes)
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
setwd("C:/Users/janch/OneDrive/Desktop/Uni/BachelorThesis/thesis-morphemepiece-port")
write.csv(vocab_split, file="vocabulary.csv", row.names=TRUE)
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
setwd("C:/Users/janch/OneDrive/Desktop/Uni/BachelorThesis/thesis-morphemepiece-port")
write.csv(vocab_split$prefixes, file="prefixes.csv", row.names=TRUE)
write.csv(vocab_split$suffixes, file="suffixes.csv", row.names=TRUE)
write.csv(vocab_split$words, file="words.csv", row.names=TRUE)
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
setwd("C:/Users/janch/OneDrive/Desktop/Uni/BachelorThesis/thesis-morphemepiece-port")
write.csv(vocab_split$prefixes, file="prefixes.csv", row.names=FALSE)
library("morphemepiece")
raw_voc<-morphemepiece_vocab()
vocab_split<-attr(raw_voc, "vocab_split")
setwd("C:/Users/janch/OneDrive/Desktop/Uni/BachelorThesis/thesis-morphemepiece-port")
write.csv(vocab_split$prefixes, file="prefixes.csv", row.names=FALSE)
write.csv(vocab_split$suffixes, file="suffixes.csv", row.names=FALSE)
write.csv(vocab_split$words, file="words.csv", row.names=FALSE)
View(vocab_split)
library("morphemepiece")
tokenized_text<-morphemepiece_tokenize(text="Hello there, this is awesome, to be here in this town")
print(tokenized_text)
print(vocab_split$prefixes)
library("morphemepiece")
tokenized_text<-morphemepiece_tokenize(text="When you create FIAT backed cryptocurrency using our tokenizer, the respective logic of the backing currency is embedded in the Smart contract automatically")
print(tokenized_text)
library(morphemepiece)
raw_voc<-morphemepiece_vocab()
print(raw_voc)
